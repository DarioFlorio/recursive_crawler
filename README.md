# Python recursive_crawler
#A python recursive crawler 
#This is a simple recursive crawler
#To use there the method crawl takes to arguments, a list of links, and the domain name of the website that need crawling.
#There is no set limit for recursiveness so bare that in mind
#The crawler will go on the given starting url then will save all the found urls into a list whilst avoiding duplicates
#Also it will save the list of found links onto a file called urls.txt



#Example usage

#url_list=["https://www.myexamplewebsite.com"]
#domain = "myexamplewebsite.com"
#crawl(url_list, domain)
